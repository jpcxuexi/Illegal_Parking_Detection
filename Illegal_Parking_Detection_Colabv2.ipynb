{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gericoaron/Illegal_Parking_Detection/blob/main/Illegal_Parking_Detection_Colabv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNAz1_HbfCQ2"
      },
      "source": [
        "# ***Illegal Parking Detection***\n",
        "\n",
        "\n",
        ">*The goal is to detect vehicle especially cars when it parked on a illegal parking space. Using YOLOv5 for experimenting and training to create our new model that is accurate on detecting cars.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLwyAQ0_ohXS",
        "outputId": "138e53a4-03ec-4f93-fb96-b46616abefa8"
      },
      "source": [
        "#Mounting Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2Was3heKH9x",
        "outputId": "ee27f38f-e921-4b27-807d-d067b90e9975"
      },
      "source": [
        "%cd /content/yolov5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "***Clone repo, install dependencies and check PyTorch and GPU.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3436f7-9f26-4387-b5c2-6673d2290440"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu111 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVJkDKTzXnTd"
      },
      "source": [
        "#unzip dataset\n",
        "!unzip -q ../train_datav2.zip -d ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "***Inference***\n",
        "\n",
        "*`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:*\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                   file.jpg  # image \n",
        "                   file.mp4  # video\n",
        "                      path/  # directory\n",
        "                 path/*.jpg  # glob\n",
        "           '{youtube link}'  # YouTube\n",
        "              '{RTSP link}'  # RTSP, RTMP, HTTP stream \n",
        "                         (rtsp://example.com/media.mp4)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX"
      },
      "source": [
        "#detect / inference\n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source data/images/\n",
        "\n",
        "#display result\n",
        "Image(filename='runs/detect/exp/cars.jpg', width=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH"
      },
      "source": [
        "# Run validation to your model using coco or custom data\n",
        "!python val.py --weights yolov5x.pt --data coco.yaml --img 640 --iou 0.65 --half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "source": [
        "# Tensorboard  (optional)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fLAV42oNb7M"
      },
      "source": [
        "# Weights & Biases  (optional)\n",
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c598ddde-f799-49c9-c028-338782a70297"
      },
      "source": [
        "#Model Training\n",
        "!python train.py --img 640 --batch 64 --epochs 100 --data custom_data.yaml --weights yolocarv2.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Installing collected packages: PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/drive/My Drive/car_parking_yolov5/yolov5/smart-car-parking-yolov5/yolov5-robo/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 515, in <module>\n",
            "    opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n",
            "  File \"/content/drive/MyDrive/car_parking_yolov5/yolov5/smart-car-parking-yolov5/yolov5-robo/utils/general.py\", line 168, in check_file\n",
            "    assert len(files), f'File Not Found: {file}'  # assert file was found\n",
            "AssertionError: File Not Found: custom_data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm3UM2SpIkS1",
        "outputId": "31f84ca4-7b3a-46df-951b-410bf238c0f7"
      },
      "source": [
        "%cd /content/drive/MyDrive/car_parking_yolov5/yolov5/smart-car-parking-yolov5/yolov5-robo\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/car_parking_yolov5/yolov5/smart-car-parking-yolov5/yolov5-robo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "***Visualize***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLI1JmHU7B0l"
      },
      "source": [
        "***Weights & Biases Logging***\n",
        "\n",
        "[Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_notebook) (W&B) for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration for teams. \n",
        "\n",
        "*enable W&B `pip install wandb`, and then train normally (you will be guided through setup on first use).* \n",
        "\n",
        "During training live updates will show at [https://wandb.ai/home](https://wandb.ai/home?utm_campaign=repo_yolo_notebook), and we can create and share detailed [Reports](https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY) of your results. \n",
        "\n",
        "*Link for more details* [YOLOv5 Weights & Biases Tutorial](https://github.com/ultralytics/yolov5/issues/1289). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WPvRbS5Swl6"
      },
      "source": [
        "## Local Logging\n",
        "\n",
        "All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and val jpgs to see mosaics, labels, predictions and augmentation effects.\n",
        "\n",
        ">\n",
        "Training results are automatically logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and [CSV](https://github.com/ultralytics/yolov5/pull/4148) as `results.csv`, which is plotted as `results.png` (below) after training completes. You can also plot any `results.csv` file manually:\n",
        "\n",
        "```python\n",
        "from utils.plots import plot_results \n",
        "plot_results('path/to/results.csv')  # plot 'results.csv' as 'results.png'\n",
        "```\n",
        "\n",
        "<img align=\"left\" width=\"800\" alt=\"COCO128 Training Results\" src=\"https://user-images.githubusercontent.com/26833433/126906780-8c5e2990-6116-4de6-b78a-367244a33ccf.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zelyeqbyt3GD"
      },
      "source": [
        "*Environments*\n",
        "\n",
        "*YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled)*\n",
        "\n",
        "- **Google Colab and Kaggle** notebooks with free GPU: <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)\n",
        "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)\n",
        "- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qu7Iesl0p54"
      },
      "source": [
        "*Status*\n",
        "\n",
        "![CI CPU testing](https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg)\n",
        "\n",
        "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([val.py](https://github.com/ultralytics/yolov5/blob/master/val.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/export.py)) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXPzH9MDm7qt"
      },
      "source": [
        "***Object Tracking***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqr1yDxVggYp",
        "outputId": "e0e41790-ceff-49fc-c501-877932c66c44"
      },
      "source": [
        "!git clone --recurse-submodules https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Yolov5_DeepSort_Pytorch'...\n",
            "remote: Enumerating objects: 904, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/898)\u001b[K\rremote: Counting objects:   1% (9/898)\u001b[K\rremote: Counting objects:   2% (18/898)\u001b[K\rremote: Counting objects:   3% (27/898)\u001b[K\rremote: Counting objects:   4% (36/898)\u001b[K\rremote: Counting objects:   5% (45/898)\u001b[K\rremote: Counting objects:   6% (54/898)\u001b[K\rremote: Counting objects:   7% (63/898)\u001b[K\rremote: Counting objects:   8% (72/898)\u001b[K\rremote: Counting objects:   9% (81/898)\u001b[K\rremote: Counting objects:  10% (90/898)\u001b[K\rremote: Counting objects:  11% (99/898)\u001b[K\rremote: Counting objects:  12% (108/898)\u001b[K\rremote: Counting objects:  13% (117/898)\u001b[K\rremote: Counting objects:  14% (126/898)\u001b[K\rremote: Counting objects:  15% (135/898)\u001b[K\rremote: Counting objects:  16% (144/898)\u001b[K\rremote: Counting objects:  17% (153/898)\u001b[K\rremote: Counting objects:  18% (162/898)\u001b[K\rremote: Counting objects:  19% (171/898)\u001b[K\rremote: Counting objects:  20% (180/898)\u001b[K\rremote: Counting objects:  21% (189/898)\u001b[K\rremote: Counting objects:  22% (198/898)\u001b[K\rremote: Counting objects:  23% (207/898)\u001b[K\rremote: Counting objects:  24% (216/898)\u001b[K\rremote: Counting objects:  25% (225/898)\u001b[K\rremote: Counting objects:  26% (234/898)\u001b[K\rremote: Counting objects:  27% (243/898)\u001b[K\rremote: Counting objects:  28% (252/898)\u001b[K\rremote: Counting objects:  29% (261/898)\u001b[K\rremote: Counting objects:  30% (270/898)\u001b[K\rremote: Counting objects:  31% (279/898)\u001b[K\rremote: Counting objects:  32% (288/898)\u001b[K\rremote: Counting objects:  33% (297/898)\u001b[K\rremote: Counting objects:  34% (306/898)\u001b[K\rremote: Counting objects:  35% (315/898)\u001b[K\rremote: Counting objects:  36% (324/898)\u001b[K\rremote: Counting objects:  37% (333/898)\u001b[K\rremote: Counting objects:  38% (342/898)\u001b[K\rremote: Counting objects:  39% (351/898)\u001b[K\rremote: Counting objects:  40% (360/898)\u001b[K\rremote: Counting objects:  41% (369/898)\u001b[K\rremote: Counting objects:  42% (378/898)\u001b[K\rremote: Counting objects:  43% (387/898)\u001b[K\rremote: Counting objects:  44% (396/898)\u001b[K\rremote: Counting objects:  45% (405/898)\u001b[K\rremote: Counting objects:  46% (414/898)\u001b[K\rremote: Counting objects:  47% (423/898)\u001b[K\rremote: Counting objects:  48% (432/898)\u001b[K\rremote: Counting objects:  49% (441/898)\u001b[K\rremote: Counting objects:  50% (449/898)\u001b[K\rremote: Counting objects:  51% (458/898)\u001b[K\rremote: Counting objects:  52% (467/898)\u001b[K\rremote: Counting objects:  53% (476/898)\u001b[K\rremote: Counting objects:  54% (485/898)\u001b[K\rremote: Counting objects:  55% (494/898)\u001b[K\rremote: Counting objects:  56% (503/898)\u001b[K\rremote: Counting objects:  57% (512/898)\u001b[K\rremote: Counting objects:  58% (521/898)\u001b[K\rremote: Counting objects:  59% (530/898)\u001b[K\rremote: Counting objects:  60% (539/898)\u001b[K\rremote: Counting objects:  61% (548/898)\u001b[K\rremote: Counting objects:  62% (557/898)\u001b[K\rremote: Counting objects:  63% (566/898)\u001b[K\rremote: Counting objects:  64% (575/898)\u001b[K\rremote: Counting objects:  65% (584/898)\u001b[K\rremote: Counting objects:  66% (593/898)\u001b[K\rremote: Counting objects:  67% (602/898)\u001b[K\rremote: Counting objects:  68% (611/898)\u001b[K\rremote: Counting objects:  69% (620/898)\u001b[K\rremote: Counting objects:  70% (629/898)\u001b[K\rremote: Counting objects:  71% (638/898)\u001b[K\rremote: Counting objects:  72% (647/898)\u001b[K\rremote: Counting objects:  73% (656/898)\u001b[K\rremote: Counting objects:  74% (665/898)\u001b[K\rremote: Counting objects:  75% (674/898)\u001b[K\rremote: Counting objects:  76% (683/898)\u001b[K\rremote: Counting objects:  77% (692/898)\u001b[K\rremote: Counting objects:  78% (701/898)\u001b[K\rremote: Counting objects:  79% (710/898)\u001b[K\rremote: Counting objects:  80% (719/898)\u001b[K\rremote: Counting objects:  81% (728/898)\u001b[K\rremote: Counting objects:  82% (737/898)\u001b[K\rremote: Counting objects:  83% (746/898)\u001b[K\rremote: Counting objects:  84% (755/898)\u001b[K\rremote: Counting objects:  85% (764/898)\u001b[K\rremote: Counting objects:  86% (773/898)\u001b[K\rremote: Counting objects:  87% (782/898)\u001b[K\rremote: Counting objects:  88% (791/898)\u001b[K\rremote: Counting objects:  89% (800/898)\u001b[K\rremote: Counting objects:  90% (809/898)\u001b[K\rremote: Counting objects:  91% (818/898)\u001b[K\rremote: Counting objects:  92% (827/898)\u001b[K\rremote: Counting objects:  93% (836/898)\u001b[K\rremote: Counting objects:  94% (845/898)\u001b[K\rremote: Counting objects:  95% (854/898)\u001b[K\rremote: Counting objects:  96% (863/898)\u001b[K\rremote: Counting objects:  97% (872/898)\u001b[K\rremote: Counting objects:  98% (881/898)\u001b[K\rremote: Counting objects:  99% (890/898)\u001b[K\rremote: Counting objects: 100% (898/898)\u001b[K\rremote: Counting objects: 100% (898/898), done.\u001b[K\n",
            "remote: Compressing objects: 100% (427/427), done.\u001b[K\n",
            "remote: Total 904 (delta 414), reused 877 (delta 409), pack-reused 6\u001b[K\n",
            "Receiving objects: 100% (904/904), 25.71 MiB | 29.88 MiB/s, done.\n",
            "Resolving deltas: 100% (414/414), done.\n",
            "Submodule 'yolov5' (https://github.com/ultralytics/yolov5.git) registered for path 'yolov5'\n",
            "Cloning into '/content/yolov5/Yolov5_DeepSort_Pytorch/yolov5'...\n",
            "remote: Enumerating objects: 9751, done.        \n",
            "remote: Total 9751 (delta 0), reused 0 (delta 0), pack-reused 9751        \n",
            "Receiving objects: 100% (9751/9751), 9.95 MiB | 24.21 MiB/s, done.\n",
            "Resolving deltas: 100% (6789/6789), done.\n",
            "Submodule path 'yolov5': checked out 'aa1859909c96d5e1fc839b2746b45038ee8465c9'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMKichZ-ghPZ",
        "outputId": "143e13b8-df3a-4872-f489-54d64ab74da2"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (5.4.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.41.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKFC-yIDgluD",
        "outputId": "1ad00a79-8c78-4512-fda9-6929938fe2a7"
      },
      "source": [
        "!python3 track.py --source /content/drive/MyDrive/car_parking_yolov5/yolov5/smart-car-parking-yolov5/yolov5-robo/cars.mp4 --yolo_weights /content/drive/MyDrive/car_parking_yolov5/yolov5/smart-car-parking-yolov5/yolov5-robo/yolocarv2.pt --classes 2 --save-vid"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ WARN:0] global /io/opencv/modules/videoio/src/cap_v4l.cpp (802) open VIDEOIO ERROR: V4L: can't open camera by index 0\n",
            "1/1: 0... Traceback (most recent call last):\n",
            "  File \"track.py\", line 216, in <module>\n",
            "    detect(args)\n",
            "  File \"track.py\", line 68, in detect\n",
            "    dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
            "  File \"/content/yolov5/Yolov5_DeepSort_Pytorch/yolov5/utils/datasets.py\", line 304, in __init__\n",
            "    assert cap.isOpened(), f'Failed to open {s}'\n",
            "AssertionError: Failed to open 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNvUE-uphK0n",
        "outputId": "7cd1e4f7-0a22-4a75-fe86-0fa194a79f26"
      },
      "source": [
        "%cd /content/yolov5/Yolov5_DeepSort_Pytorch\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5/Yolov5_DeepSort_Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZFNVvYhLqc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}